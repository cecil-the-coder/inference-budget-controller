{"id":"inference-budget-controller-3bv","title":"Replace typed request structs with minimal inferenceRequest","description":"Replace ChatCompletionRequest and CompletionRequest with a minimal struct that only extracts 'model' and 'stream' fields using json.RawMessage for the rest. This avoids full deserialization of request bodies we just forward to backends, improving performance and ensuring automatic compatibility with all current and future OpenAI API fields (tool calls, multimodal content, max_completion_tokens, etc.).","status":"closed","priority":1,"issue_type":"task","owner":"cecilthecoder@proton.me","created_at":"2026-02-27T16:03:08.854942379-07:00","created_by":"Cecil","updated_at":"2026-02-27T16:07:07.284896155-07:00","closed_at":"2026-02-27T16:07:07.284896155-07:00","close_reason":"Added inferenceRequest struct to openai.go. Updated both handlers and forwarders in handler.go to use it with json.Unmarshal instead of ShouldBindJSON. Builds and tests pass."}
{"id":"inference-budget-controller-745","title":"Add pass-through routes for /v1/embeddings and /v1/audio/transcriptions","description":"Add generic pass-through routes for the remaining OpenAI-compatible endpoints listed in INFERENCE_PROXY.md Phase 4. With the new generic handler these become simple route registrations — same model lookup, budget check, scale-up, and byte-for-byte forwarding logic. The /v1/audio/transcriptions endpoint uses multipart/form-data so the model field must be extracted from form data rather than JSON.","status":"closed","priority":2,"issue_type":"feature","owner":"cecilthecoder@proton.me","created_at":"2026-02-27T16:03:20.010961952-07:00","created_by":"Cecil","updated_at":"2026-02-27T16:13:33.472766097-07:00","closed_at":"2026-02-27T16:13:33.472766097-07:00","close_reason":"Added /v1/embeddings route using openaiPassthroughHandler (JSON body). Added /v1/audio/transcriptions route using new multipartPassthroughHandler that extracts model from form data and forwards the raw multipart request via forwardRawRequest. Build and tests pass.","dependencies":[{"issue_id":"inference-budget-controller-745","depends_on_id":"inference-budget-controller-bld","type":"blocks","created_at":"2026-02-27T16:03:24.338879493-07:00","created_by":"Cecil"}]}
{"id":"inference-budget-controller-7mp","title":"On-demand deployment creation for inference proxy","description":"Implement true serverless inference where deployments are created on-demand when requests arrive, rather than keeping all deployments scaled to 0.","status":"closed","priority":2,"issue_type":"epic","owner":"cecilthecoder@proton.me","created_at":"2026-02-28T14:28:09.613224187Z","created_by":"Cecil","updated_at":"2026-02-28T14:58:50.359105273Z","closed_at":"2026-02-28T14:58:50.359105273Z","close_reason":"Closed","labels":["inference","proxy","serverless"]}
{"id":"inference-budget-controller-7mp.1","title":"Add DeploymentRegistry to track deployment state in memory","description":"Create a thread-safe registry in the controller that tracks which deployments exist and their state. This avoids needing to query K8s API to check if a deployment exists.\n\nThe registry should track:\n- Deployment name/namespace\n- State (creating, ready, deleting, nonexistent)\n- Last request timestamp\n- Active request count\n\nThis registry will be shared between the controller (which updates it) and the proxy (which queries it).","status":"closed","priority":2,"issue_type":"feature","owner":"cecilthecoder@proton.me","estimated_minutes":30,"created_at":"2026-02-28T14:28:23.226373713Z","created_by":"Cecil","updated_at":"2026-02-28T14:33:06.733910767Z","closed_at":"2026-02-28T14:33:06.733910767Z","close_reason":"Closed","labels":["inference","registry"],"dependencies":[{"issue_id":"inference-budget-controller-7mp.1","depends_on_id":"inference-budget-controller-7mp","type":"parent-child","created_at":"2026-02-28T14:28:23.227618946Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-7mp.2","title":"Update controller to maintain DeploymentRegistry","description":"Modify the InferenceModelReconciler to update the DeploymentRegistry when:\n- Deployment is created → state=creating\n- Deployment pods are ready → state=ready\n- Deployment is deleted → state=nonexistent\n- Request annotation is updated → update lastRequest timestamp\n\nThe registry should be passed to both the controller and proxy at startup.","status":"closed","priority":2,"issue_type":"feature","owner":"cecilthecoder@proton.me","estimated_minutes":30,"created_at":"2026-02-28T14:28:33.698938661Z","created_by":"Cecil","updated_at":"2026-02-28T14:41:13.875250517Z","closed_at":"2026-02-28T14:41:13.875250517Z","close_reason":"Closed","labels":["controller","inference"],"dependencies":[{"issue_id":"inference-budget-controller-7mp.2","depends_on_id":"inference-budget-controller-7mp","type":"parent-child","created_at":"2026-02-28T14:28:33.700244066Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-7mp.2","depends_on_id":"inference-budget-controller-7mp.1","type":"blocks","created_at":"2026-02-28T14:28:33.701860883Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-7mp.3","title":"Update proxy handler for on-demand deployment creation","description":"Modify the proxy handler to:\n1. Check DeploymentRegistry for deployment state\n2. If state=nonexistent, trigger deployment creation via K8s API\n3. If state=creating, wait for state=ready with timeout\n4. If state=ready, forward request to backend\n5. Update lastRequest timestamp in registry after successful request\n\nHandle edge cases:\n- Timeout waiting for ready (return 503)\n- Failed deployment creation (return 500)\n- Concurrent requests for same cold model (single-flight pattern)","status":"closed","priority":2,"issue_type":"feature","owner":"cecilthecoder@proton.me","estimated_minutes":60,"created_at":"2026-02-28T14:28:46.3594193Z","created_by":"Cecil","updated_at":"2026-02-28T14:53:44.624967086Z","closed_at":"2026-02-28T14:53:44.624967086Z","close_reason":"Closed","labels":["inference","proxy"],"dependencies":[{"issue_id":"inference-budget-controller-7mp.3","depends_on_id":"inference-budget-controller-7mp","type":"parent-child","created_at":"2026-02-28T14:28:46.360554739Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-7mp.3","depends_on_id":"inference-budget-controller-7mp.2","type":"blocks","created_at":"2026-02-28T14:28:46.362181123Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-7mp.4","title":"Delete idle deployments instead of scaling to 0","description":"Change the idle scaling behavior:\n- Instead of scaling deployment to 0 replicas, delete the deployment entirely\n- Also delete the associated Service\n- Update DeploymentRegistry state to nonexistent\n\nThis provides true serverless behavior with zero resource usage when idle.","status":"closed","priority":2,"issue_type":"feature","owner":"cecilthecoder@proton.me","estimated_minutes":20,"created_at":"2026-02-28T14:28:56.976644917Z","created_by":"Cecil","updated_at":"2026-02-28T14:53:44.687445621Z","closed_at":"2026-02-28T14:53:44.687445621Z","close_reason":"Closed","labels":["inference","scaling"],"dependencies":[{"issue_id":"inference-budget-controller-7mp.4","depends_on_id":"inference-budget-controller-7mp","type":"parent-child","created_at":"2026-02-28T14:28:56.977677103Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-7mp.4","depends_on_id":"inference-budget-controller-7mp.2","type":"blocks","created_at":"2026-02-28T14:28:56.979191208Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-7mp.5","title":"Migration: delete existing scaled-to-zero deployments","description":"As part of deploying the on-demand feature:\n1. Delete all existing deployments that are scaled to 0\n2. Delete their associated Services\n3. Let the new on-demand logic recreate them when needed\n\nThis cleans up the old 'always exist but scaled to 0' model.","status":"closed","priority":2,"issue_type":"task","owner":"cecilthecoder@proton.me","estimated_minutes":10,"created_at":"2026-02-28T14:29:07.503333675Z","created_by":"Cecil","updated_at":"2026-02-28T14:58:50.287356129Z","closed_at":"2026-02-28T14:58:50.287356129Z","close_reason":"Closed","labels":["inference","migration"],"dependencies":[{"issue_id":"inference-budget-controller-7mp.5","depends_on_id":"inference-budget-controller-7mp","type":"parent-child","created_at":"2026-02-28T14:29:07.504689494Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-7mp.5","depends_on_id":"inference-budget-controller-7mp.4","type":"blocks","created_at":"2026-02-28T14:29:07.507302229Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-bld","title":"Unify chat/completion handlers into generic pass-through handler","description":"The chatCompletionsHandler and completionsHandler are nearly identical — they differ only in the typed struct and the backend URL path. Unify them into a single generic handler that takes the backend path as a parameter. Similarly merge forwardRequest and forwardCompletionRequest into one function. This eliminates ~150 lines of duplicated code.","status":"closed","priority":1,"issue_type":"task","owner":"cecilthecoder@proton.me","created_at":"2026-02-27T16:03:11.844990128-07:00","created_by":"Cecil","updated_at":"2026-02-27T16:11:49.087819339-07:00","closed_at":"2026-02-27T16:11:49.087819339-07:00","close_reason":"Handlers unified into openaiPassthroughHandler + forwardToBackend. All unused OpenAI types deleted. Build and tests pass.","dependencies":[{"issue_id":"inference-budget-controller-bld","depends_on_id":"inference-budget-controller-3bv","type":"blocks","created_at":"2026-02-27T16:03:24.199677802-07:00","created_by":"Cecil"}]}
{"id":"inference-budget-controller-s5d","title":"Inference Budget Controller Implementation","description":"Implement the complete Inference Budget Controller - a Kubernetes operator that provides memory-aware scaling and admission control for LLM inference workloads.\n\n## Overview\n\nBuild a Kubernetes operator that:\n- Provides memory-aware scaling for LLM inference workloads\n- Implements cross-model coordination for shared memory\n- Offers admission control with fast 429 responses\n- Tracks actual memory usage and provides recommendations\n\n## Key Components\n\n1. **InferenceModel CRD** - Custom resource for declaring models with memory requirements\n2. **Controller** - Reconciliation loop managing Deployments\n3. **Budget Tracker** - In-memory memory allocation tracking\n4. **API Proxy** - OpenAI-compatible endpoint with admission control\n5. **Observability** - Metrics, logging, and status for usage recommendations\n\n## Deliverables\n\n- Fully functional Kubernetes operator\n- Comprehensive unit and e2e tests\n- Pre-commit hooks for quality gates\n- GitHub workflow for CI/CD\n- Documentation","status":"closed","priority":0,"issue_type":"epic","owner":"cecilthecoder@proton.me","created_at":"2026-02-27T02:48:52.610830112Z","created_by":"Cecil","updated_at":"2026-02-27T04:00:58.082354253Z","closed_at":"2026-02-27T04:00:58.082354253Z","close_reason":"Closed"}
{"id":"inference-budget-controller-s5d.1","title":"Project Scaffolding and Dependencies","description":"Set up the initial project structure and install all required dependencies.\n\n## Tasks\n\n1. **Initialize Go module**\n   - Run `go mod init github.com/eh-ops/inference-budget-controller`\n   - Set Go version to 1.21+\n\n2. **Install kubebuilder or controller-runtime**\n   - Use kubebuilder v3 or controller-runtime v0.17+\n   - Set up Makefile with standard targets\n\n3. **Create directory structure**\n   ```\n   api/v1alpha1/\n   cmd/\n   internal/controller/\n   internal/proxy/\n   internal/budget/\n   internal/metrics/\n   config/crd/\n   config/rbac/\n   config/manager/\n   ```\n\n4. **Install dependencies**\n   - `controller-runtime` for operator framework\n   - `gin` or `echo` for HTTP proxy\n   - `prometheus/client_golang` for metrics\n   - `k8s.io/client-go` for Kubernetes client\n\n5. **Create Dockerfile**\n   - Multi-stage build with Go\n   - Minimal base image (distroless or alpine)\n\n6. **Create Makefile targets**\n   - `make build` - Build the binary\n   - `make test` - Run unit tests\n   - `make lint` - Run linters\n   - `make docker-build` - Build Docker image\n   - `make generate` - Generate deepcopy functions\n   - `make manifests` - Generate CRD manifests\n\n## Acceptance Criteria\n\n- [ ] Go module initialized\n- [ ] Directory structure matches design\n- [ ] Makefile with all standard targets\n- [ ] Dockerfile created\n- [ ] All dependencies installable via `go mod download`","status":"closed","priority":0,"issue_type":"task","owner":"cecilthecoder@proton.me","estimated_minutes":60,"created_at":"2026-02-27T02:49:48.586825774Z","created_by":"Cecil","updated_at":"2026-02-27T03:26:21.454280381Z","closed_at":"2026-02-27T03:26:21.454284058Z","dependencies":[{"issue_id":"inference-budget-controller-s5d.1","depends_on_id":"inference-budget-controller-s5d","type":"parent-child","created_at":"2026-02-27T02:49:48.588136998Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-s5d.10","title":"Documentation and Examples","description":"Create comprehensive documentation and example configurations.\n\n## Documentation Structure\n\n```\ndocs/\n├── getting-started.md      # Installation and quick start\n├── crd-reference.md        # InferenceModel CRD reference\n├── architecture.md         # System architecture overview\n├── admission-control.md    # How admission control works\n├── observability.md        # Metrics and monitoring guide\n├── troubleshooting.md      # Common issues and solutions\n└── examples/\n    ├── basic-model.yaml    # Simple model example\n    ├── multi-node.yaml     # Multi-node configuration\n    ├── custom-resources.yaml\n    └── prometheus.yaml     # Prometheus scrape config\n```\n\n## README Updates\n\n- Add quick start section\n- Add prerequisites (Kubernetes version, etc.)\n- Add installation instructions\n- Add basic usage examples\n- Link to detailed docs\n\n## Example InferenceModel\n\n```yaml\napiVersion: inference.eh-ops.io/v1alpha1\nkind: InferenceModel\nmetadata:\n  name: llama-2-70b\nspec:\n  modelName: llama-2-70b-chat\n  memoryRequired: 80Gi\n  image: ghcr.io/eh-ops/vllm:latest\n  nodeSelector:\n    node-type: gpu\n  scaleToZero:\n    enabled: true\n    idleTimeoutSeconds: 300\n    cooldownPeriodSeconds: 60\n  port: 8000\n  env:\n    - name: MODEL_NAME\n      value: llama-2-70b-chat\n  resources:\n    requests:\n      cpu: \"4\"\n      nvidia.com/gpu: \"1\"\n    limits:\n      cpu: \"8\"\n      nvidia.com/gpu: \"1\"\n```\n\n## Tasks\n\n1. Create docs/ directory structure\n2. Write getting-started.md\n3. Write CRD reference documentation\n4. Write architecture overview\n5. Write admission control guide\n6. Write observability guide\n7. Create example YAML files\n8. Update main README.md\n\n## Acceptance Criteria\n\n- [ ] All doc files created\n- [ ] Examples are valid YAML\n- [ ] Getting started guide is complete and accurate\n- [ ] CRD reference covers all fields\n- [ ] README updated with quick start","status":"closed","priority":2,"issue_type":"task","owner":"cecilthecoder@proton.me","estimated_minutes":60,"created_at":"2026-02-27T02:54:24.675472367Z","created_by":"Cecil","updated_at":"2026-02-27T04:00:39.616715671Z","closed_at":"2026-02-27T04:00:39.616718687Z","dependencies":[{"issue_id":"inference-budget-controller-s5d.10","depends_on_id":"inference-budget-controller-s5d","type":"parent-child","created_at":"2026-02-27T02:54:24.676813977Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-s5d.10","depends_on_id":"inference-budget-controller-s5d.4","type":"blocks","created_at":"2026-02-27T02:54:24.678883855Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-s5d.10","depends_on_id":"inference-budget-controller-s5d.5","type":"blocks","created_at":"2026-02-27T02:54:24.680865799Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-s5d.2","title":"InferenceModel CRD Definition","description":"Define the InferenceModel Custom Resource Definition with all required fields.\n\n## CRD Specification\n\n```go\ntype InferenceModelSpec struct {\n    // Model name/identifier\n    ModelName string `json:\"modelName\"`\n    \n    // Memory required by the model (e.g., \"80Gi\")\n    MemoryRequired resource.Quantity `json:\"memoryRequired\"`\n    \n    // Container image for the model server\n    Image string `json:\"image\"`\n    \n    // Node selector for placement\n    NodeSelector map[string]string `json:\"nodeSelector,omitempty\"`\n    \n    // Scale-to-zero configuration\n    ScaleToZero ScaleToZeroConfig `json:\"scaleToZero,omitempty\"`\n    \n    // Container port (default: 8080)\n    Port int32 `json:\"port,omitempty\"`\n    \n    // Environment variables\n    Env []corev1.EnvVar `json:\"env,omitempty\"`\n    \n    // Resource requests/limits (CPU, ephemeral storage)\n    Resources corev1.ResourceRequirements `json:\"resources,omitempty\"`\n}\n\ntype ScaleToZeroConfig struct {\n    // Enable scale-to-zero (default: true)\n    Enabled bool `json:\"enabled,omitempty\"`\n    \n    // Seconds of inactivity before scaling down\n    IdleTimeoutSeconds int32 `json:\"idleTimeoutSeconds,omitempty\"`\n    \n    // Cooldown period before allowing scale down\n    CooldownPeriodSeconds int32 `json:\"cooldownPeriodSeconds,omitempty\"`\n}\n\ntype InferenceModelStatus struct {\n    // Observed peak memory usage\n    ObservedPeakMemory *resource.Quantity `json:\"observedPeakMemory,omitempty\"`\n    \n    // Memory declared in spec\n    DeclaredMemory string `json:\"declaredMemory,omitempty\"`\n    \n    // Utilization percentage\n    UtilizationPercent int32 `json:\"utilizationPercent,omitempty\"`\n    \n    // Human-readable recommendation\n    Recommendation string `json:\"recommendation,omitempty\"`\n    \n    // Last observation timestamp\n    LastObservation *metav1.Time `json:\"lastObservation,omitempty\"`\n    \n    // Current replica count\n    Replicas int32 `json:\"replicas\"`\n    \n    // Conditions\n    Conditions []metav1.Condition `json:\"conditions,omitempty\"`\n}\n```\n\n## Tasks\n\n1. Create `api/v1alpha1/inferencemodel_types.go`\n2. Create `api/v1alpha1/groupversion_info.go`\n3. Run `make generate` to create deepcopy functions\n4. Run `make manifests` to generate CRD YAML\n5. Create example InferenceModel in `config/samples/`\n\n## Acceptance Criteria\n\n- [ ] CRD types defined with all fields\n- [ ] DeepCopy functions generated\n- [ ] CRD manifest generated in `config/crd/bases/`\n- [ ] Example resource created\n- [ ] CRD passes `kubectl apply --dry-run`","status":"closed","priority":0,"issue_type":"feature","owner":"cecilthecoder@proton.me","estimated_minutes":90,"created_at":"2026-02-27T02:49:48.739169594Z","created_by":"Cecil","updated_at":"2026-02-27T03:43:17.750871431Z","closed_at":"2026-02-27T03:43:17.750877051Z","dependencies":[{"issue_id":"inference-budget-controller-s5d.2","depends_on_id":"inference-budget-controller-s5d","type":"parent-child","created_at":"2026-02-27T02:49:48.73988139Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-s5d.3","title":"Budget Tracker Implementation","description":"Implement the in-memory budget tracker that manages memory allocation per node.\n\n## Overview\n\nThe Budget Tracker is responsible for:\n- Tracking memory allocation per node\n- Checking if a model can fit on a node\n- Recording actual memory usage observations\n- Providing utilization metrics\n\n## API Design\n\n```go\npackage budget\n\ntype Tracker interface {\n    // Allocate reserves memory for a model on a node\n    Allocate(nodeName, modelName string, memory resource.Quantity) error\n    \n    // Release frees memory for a model on a node\n    Release(nodeName, modelName string) error\n    \n    // CanFit checks if a model can fit on a node\n    CanFit(nodeName string, memory resource.Quantity) (bool, AvailableInfo)\n    \n    // GetBlocking returns models blocking allocation on a node\n    GetBlocking(nodeName string) []ModelInfo\n    \n    // RecordUsage records observed memory usage for a model\n    RecordUsage(nodeName, modelName string, observed resource.Quantity)\n    \n    // GetUtilization returns utilization metrics for a model\n    GetUtilization(nodeName, modelName string) UtilizationInfo\n}\n\ntype AvailableInfo struct {\n    Available     resource.Quantity\n    Total         resource.Quantity\n    BlockingModels []ModelInfo\n}\n\ntype ModelInfo struct {\n    Name         string\n    Memory       resource.Quantity\n    IdleDuration time.Duration\n}\n\ntype UtilizationInfo struct {\n    Declared     resource.Quantity\n    ObservedPeak resource.Quantity\n    Utilization  float64\n    Recommendation string\n}\n```\n\n## Implementation Details\n\n1. **Thread-safe**: Use sync.RWMutex for concurrent access\n2. **Per-node capacity**: Configurable via config/CLI flag\n3. **Peak tracking**: Track peak memory per model over time\n4. **Recommendation engine**: Calculate if declared memory can be reduced\n\n## Tasks\n\n1. Create `internal/budget/tracker.go` with Tracker interface\n2. Implement in-memory tracker with mutex protection\n3. Add node capacity configuration\n4. Implement peak memory tracking\n5. Implement recommendation calculation (e.g., 10% buffer over observed peak)\n6. Create `internal/budget/tracker_test.go` with comprehensive tests\n\n## Acceptance Criteria\n\n- [ ] Tracker interface defined\n- [ ] Thread-safe implementation\n- [ ] Unit tests with \u003e90% coverage\n- [ ] Can calculate recommendations based on observed vs declared\n- [ ] Handles edge cases (zero memory, negative, overflow)","status":"closed","priority":0,"issue_type":"feature","owner":"cecilthecoder@proton.me","estimated_minutes":120,"created_at":"2026-02-27T02:50:46.465811192Z","created_by":"Cecil","updated_at":"2026-02-27T03:43:17.782152407Z","closed_at":"2026-02-27T03:43:17.782155903Z","dependencies":[{"issue_id":"inference-budget-controller-s5d.3","depends_on_id":"inference-budget-controller-s5d","type":"parent-child","created_at":"2026-02-27T02:50:46.467222793Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-s5d.4","title":"InferenceModel Controller Implementation","description":"Implement the Kubernetes controller that reconciles InferenceModel CRDs.\n\n## Overview\n\nThe Controller:\n- Watches InferenceModel CRDs\n- Creates/updates/deletes underlying Deployments\n- Scales between 0 and 1 replicas based on traffic\n- Coordinates with Budget Tracker for memory management\n\n## Controller Logic\n\n```go\nfunc (r *InferenceModelReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {\n    // 1. Fetch InferenceModel\n    model := \u0026inferencev1alpha1.InferenceModel{}\n    if err := r.Get(ctx, req.NamespacedName, model); err != nil {\n        return ctrl.Result{}, client.IgnoreNotFound(err)\n    }\n    \n    // 2. Check if being deleted\n    if !model.DeletionTimestamp.IsZero() {\n        return r.handleDeletion(ctx, model)\n    }\n    \n    // 3. Ensure finalizer\n    if err := r.ensureFinalizer(ctx, model); err != nil {\n        return ctrl.Result{}, err\n    }\n    \n    // 4. Get or create Deployment\n    deploy, err := r.getOrCreateDeployment(ctx, model)\n    if err != nil {\n        return ctrl.Result{}, err\n    }\n    \n    // 5. Register with budget tracker\n    r.Tracker.RecordUsage(model.Spec.NodeSelector, model.Name, model.Status.ObservedPeakMemory)\n    \n    // 6. Update status\n    return r.updateStatus(ctx, model, deploy)\n}\n```\n\n## Scaling Logic\n\n- **Scale to 1**: When request arrives via proxy\n- **Scale to 0**: After idle timeout + cooldown period\n- **Coordination**: Check budget tracker before scaling up\n\n## Tasks\n\n1. Create `internal/controller/inferencemodel_controller.go`\n2. Implement Reconcile loop\n3. Implement Deployment management\n4. Implement finalizer for cleanup\n5. Implement status updates\n6. Add event recording for observability\n7. Create controller tests with envtest\n\n## Acceptance Criteria\n\n- [ ] Controller reconciles InferenceModel CRDs\n- [ ] Creates/manages Deployments correctly\n- [ ] Updates InferenceModel status\n- [ ] Handles deletion with finalizers\n- [ ] Integrates with Budget Tracker\n- [ ] Envtest-based unit tests pass","status":"closed","priority":0,"issue_type":"feature","owner":"cecilthecoder@proton.me","estimated_minutes":180,"created_at":"2026-02-27T02:50:46.60172899Z","created_by":"Cecil","updated_at":"2026-02-27T03:43:17.806959929Z","closed_at":"2026-02-27T03:43:17.806963856Z","dependencies":[{"issue_id":"inference-budget-controller-s5d.4","depends_on_id":"inference-budget-controller-s5d","type":"parent-child","created_at":"2026-02-27T02:50:46.60275373Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-s5d.4","depends_on_id":"inference-budget-controller-s5d.1","type":"blocks","created_at":"2026-02-27T02:50:46.603669015Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-s5d.4","depends_on_id":"inference-budget-controller-s5d.2","type":"blocks","created_at":"2026-02-27T02:50:46.604811925Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-s5d.4","depends_on_id":"inference-budget-controller-s5d.3","type":"blocks","created_at":"2026-02-27T02:50:46.60551199Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-s5d.5","title":"API Proxy Implementation","description":"Implement the OpenAI-compatible API proxy with admission control.\n\n## Overview\n\nThe API Proxy:\n- Exposes OpenAI-compatible /v1/chat/completions endpoint\n- Implements admission control with 429 responses\n- Routes requests to model backends\n- Tracks idle time for scale-to-zero\n\n## API Endpoints\n\n```\nPOST /v1/chat/completions  - Main inference endpoint\nPOST /v1/completions       - Legacy completions endpoint\nGET  /v1/models            - List available models\nGET  /models/{name}/metrics - Get model memory metrics\nGET  /healthz              - Health check\nGET  /readyz               - Readiness check\n```\n\n## Admission Control Flow\n\n```\n1. Parse request, extract model name\n2. Look up InferenceModel CRD\n3. Check Budget Tracker: Can model fit on node?\n   - YES: Scale up if needed, forward request\n   - NO: Return 429 with details\n```\n\n## 429 Response Format\n\n```json\n{\n  \"error\": {\n    \"type\": \"insufficient_memory\",\n    \"message\": \"Cannot schedule model-b: insufficient memory\",\n    \"details\": {\n      \"requested\": {\n        \"model\": \"model-b\",\n        \"memory\": \"60Gi\"\n      },\n      \"available\": \"48Gi\",\n      \"blocking\": [\n        {\n          \"model\": \"model-a\",\n          \"memory\": \"80Gi\",\n          \"idle_for\": \"120s\"\n        }\n      ]\n    }\n  }\n}\n```\n\n## Request Routing\n\n1. Model is scaled to 0: Trigger scale up, wait for ready\n2. Model is scaling: Wait with progress updates\n3. Model is ready: Forward request to backend\n\n## Tasks\n\n1. Create `internal/proxy/server.go` - HTTP server setup\n2. Create `internal/proxy/handler.go` - Request handlers\n3. Create `internal/proxy/openai.go` - OpenAI API types\n4. Create `internal/proxy/admission.go` - Admission control logic\n5. Create `internal/proxy/routing.go` - Request routing\n6. Implement idle time tracking\n7. Write comprehensive unit tests\n\n## Acceptance Criteria\n\n- [ ] OpenAI-compatible endpoints work\n- [ ] Returns 429 with detailed error when memory insufficient\n- [ ] Routes requests to correct backends\n- [ ] Handles model cold starts\n- [ ] Tracks idle time per model\n- [ ] Unit tests with \u003e90% coverage","status":"closed","priority":0,"issue_type":"feature","owner":"cecilthecoder@proton.me","estimated_minutes":180,"created_at":"2026-02-27T02:51:41.851927063Z","created_by":"Cecil","updated_at":"2026-02-27T03:43:17.836094274Z","closed_at":"2026-02-27T03:43:17.836101858Z","dependencies":[{"issue_id":"inference-budget-controller-s5d.5","depends_on_id":"inference-budget-controller-s5d","type":"parent-child","created_at":"2026-02-27T02:51:41.853071185Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-s5d.5","depends_on_id":"inference-budget-controller-s5d.3","type":"blocks","created_at":"2026-02-27T02:51:41.854761896Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-s5d.6","title":"Observability: Metrics, Logging, and Status","description":"Implement comprehensive observability including Prometheus metrics, structured logging, and CRD status updates.\n\n## Prometheus Metrics\n\n```go\n// Memory metrics\ninference_model_memory_declared_bytes{model}     // Declared memory\ninference_model_memory_observed_peak_bytes{model} // Observed peak\ninference_model_memory_utilization_ratio{model}   // Ratio (0-1)\n\n// Controller metrics\ninference_model_replicas{model}                   // Current replica count\ninference_model_requests_total{model,status}      // Request counter\ninference_model_request_duration_seconds{model}   // Request latency\n\n// Admission control metrics\ninference_admission_requests_total{model,result}  // accepted/rejected\ninference_admission_rejected_total{model,reason}  // insufficient_memory, etc\n\n// Budget metrics\ninference_node_memory_total_bytes{node}          // Node capacity\ninference_node_memory_available_bytes{node}       // Available memory\ninference_node_memory_used_bytes{node}            // Used memory\n```\n\n## Structured Logging\n\n```\nINFO  model-a declared 80Gi but observed peak is 75Gi (6% overprovisioned)\nINFO  model-b declared 60Gi but observed peak is 58Gi (3% overprovisioned)\nINFO  Scaling model-a from 0 to 1 replicas\nINFO  Admission rejected for model-b: insufficient memory (need 60Gi, have 48Gi)\n```\n\nLog fields:\n- model: model name\n- node: node name\n- memory_declared: declared memory\n- memory_observed: observed peak\n- utilization_percent: utilization percentage\n\n## CRD Status Updates\n\n```yaml\nstatus:\n  observedPeakMemory: 75Gi\n  declaredMemory: 80Gi\n  utilizationPercent: 93\n  recommendation: \"Consider reducing memory to 78Gi for better packing\"\n  lastObservation: \"2024-01-15T10:30:00Z\"\n  replicas: 1\n  conditions:\n    - type: Available\n      status: \"True\"\n      lastTransitionTime: \"2024-01-15T10:00:00Z\"\n```\n\n## Tasks\n\n1. Create `internal/metrics/metrics.go` - Prometheus metrics\n2. Create `internal/metrics/recorder.go` - Metric recording helpers\n3. Add structured logging throughout controller/proxy\n4. Implement status update logic in controller\n5. Add /metrics endpoint to proxy\n6. Create recommendation calculation logic\n7. Write tests for metrics/recording\n\n## Acceptance Criteria\n\n- [ ] Prometheus metrics exposed on /metrics\n- [ ] Structured JSON logging with relevant fields\n- [ ] CRD status updated with observed memory\n- [ ] Recommendations generated when overprovisioned\n- [ ] Memory utilization hints logged periodically","status":"closed","priority":1,"issue_type":"feature","owner":"cecilthecoder@proton.me","estimated_minutes":120,"created_at":"2026-02-27T02:51:42.020965906Z","created_by":"Cecil","updated_at":"2026-02-27T04:00:39.552264916Z","closed_at":"2026-02-27T04:00:39.552269334Z","dependencies":[{"issue_id":"inference-budget-controller-s5d.6","depends_on_id":"inference-budget-controller-s5d","type":"parent-child","created_at":"2026-02-27T02:51:42.021683894Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-s5d.6","depends_on_id":"inference-budget-controller-s5d.3","type":"blocks","created_at":"2026-02-27T02:51:42.022589402Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-s5d.6","depends_on_id":"inference-budget-controller-s5d.4","type":"blocks","created_at":"2026-02-27T02:51:42.023449685Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-s5d.7","title":"Pre-commit Hooks Setup","description":"Set up pre-commit hooks for code quality and testing.\n\n## Hooks Configuration\n\nCreate `.pre-commit-config.yaml`:\n\n```yaml\nrepos:\n  # Go formatting\n  - repo: https://github.com/prettier/pre-commit\n    rev: v3.1.0\n    hooks:\n      - id: prettier\n        types: [go]\n        exclude: ^api/v1alpha1/zz_generated\n\n  # Go imports\n  - repo: https://github.com/incu6us/go-format\n    rev: v1.0.0\n    hooks:\n      - id: go-fmt\n      - id: go-imports\n\n  # Go linting\n  - repo: https://github.com/golangci/golangci-lint\n    rev: v1.55.2\n    hooks:\n      - id: golangci-lint\n\n  # YAML linting\n  - repo: https://github.com/adrienverge/yamllint\n    rev: v1.33.0\n    hooks:\n      - id: yamllint\n        args: [-c, .yamllint.yml]\n\n  # Shell script checking\n  - repo: https://github.com/shellcheck-py/shellcheck-py\n    rev: v0.9.0.6\n    hooks:\n      - id: shellcheck\n\n  # Run unit tests\n  - repo: local\n    hooks:\n      - id: go-test\n        name: go test\n        entry: make test\n        language: system\n        types: [go]\n        pass_filenames: false\n\n  # Generate code (deepcopy, manifests)\n  - repo: local\n    hooks:\n      - id: make-generate\n        name: make generate\n        entry: make generate\n        language: system\n        pass_filenames: false\n        files: ^api/\n\n  # Check for TODO/FIXME without issue\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: check-merge-conflict\n      - id: check-yaml\n      - id: end-of-file-fixer\n      - id: trailing-whitespace\n      - id: no-commit-to-branch\n        args: [--branch, main]\n```\n\n## Additional Configuration\n\nCreate `.golangci.yml`:\n```yaml\nlinters:\n  enable:\n    - gofmt\n    - goimports\n    - govet\n    - errcheck\n    - staticcheck\n    - ineffassign\n    - typecheck\n    - gocyclo\n    - dupl\n    - misspell\n\nlinters-settings:\n  gocyclo:\n    min-complexity: 15\n\nrun:\n  timeout: 5m\n  skip-dirs:\n    - api/v1alpha1/zz_generated\n```\n\n## Tasks\n\n1. Install pre-commit: `apt install pre-commit`\n2. Create `.pre-commit-config.yaml`\n3. Create `.golangci.yml`\n4. Create `.yamllint.yml`\n5. Run `pre-commit install` to set up git hooks\n6. Run `pre-commit run --all-files` to verify\n7. Document in README or CONTRIBUTING.md\n\n## Acceptance Criteria\n\n- [ ] Pre-commit hooks installed and working\n- [ ] All hooks pass on current codebase\n- [ ] golangci-lint configured appropriately\n- [ ] Unit tests run as part of pre-commit","status":"closed","priority":1,"issue_type":"chore","owner":"cecilthecoder@proton.me","estimated_minutes":45,"created_at":"2026-02-27T02:52:48.596553094Z","created_by":"Cecil","updated_at":"2026-02-27T03:26:21.589707456Z","closed_at":"2026-02-27T03:26:21.589710843Z","dependencies":[{"issue_id":"inference-budget-controller-s5d.7","depends_on_id":"inference-budget-controller-s5d","type":"parent-child","created_at":"2026-02-27T02:52:48.597297682Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-s5d.8","title":"GitHub Workflow: Build and Test","description":"Create GitHub Actions workflow for CI/CD pipeline.\n\n## Workflow: CI (.github/workflows/ci.yml)\n\n```yaml\nname: CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-go@v5\n        with:\n          go-version: '1.21'\n      - name: golangci-lint\n        uses: golangci/golangci-lint-action@v4\n        with:\n          version: latest\n\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-go@v5\n        with:\n          go-version: '1.21'\n      - name: Run tests\n        run: make test\n      - name: Upload coverage\n        uses: codecov/codecov-action@v4\n        with:\n          file: ./coverage.out\n\n  build:\n    runs-on: ubuntu-latest\n    needs: [lint, test]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-go@v5\n        with:\n          go-version: '1.21'\n      - name: Build\n        run: make build\n\n  e2e-test:\n    runs-on: ubuntu-latest\n    needs: [build]\n    steps:\n      - uses: actions/checkout@v4\n      - name: Run e2e tests\n        run: make test-e2e\n```\n\n## Workflow: Release (.github/workflows/release.yml)\n\n```yaml\nname: Release\n\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  build-and-push:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n      \n      - name: Login to GitHub Container Registry\n        uses: docker/login-action@v3\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n      \n      - name: Extract version\n        id: version\n        run: echo \"VERSION=${GITHUB_REF#refs/tags/}\" \u003e\u003e $GITHUB_OUTPUT\n      \n      - name: Build and push\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          push: true\n          tags: |\n            ghcr.io/eh-ops/inference-budget-controller:${{ steps.version.outputs.VERSION }}\n            ghcr.io/eh-ops/inference-budget-controller:latest\n          platforms: linux/amd64,linux/arm64\n```\n\n## Tasks\n\n1. Create `.github/workflows/ci.yml`\n2. Create `.github/workflows/release.yml`\n3. Update Makefile with coverage output\n4. Ensure all workflows use proper caching\n5. Test workflow syntax with act (optional)\n\n## Acceptance Criteria\n\n- [ ] CI workflow runs on push and PR\n- [ ] Lint, test, build stages pass\n- [ ] Coverage uploaded to codecov\n- [ ] Release workflow builds and pushes image\n- [ ] Multi-platform images supported (amd64, arm64)","status":"closed","priority":1,"issue_type":"chore","owner":"cecilthecoder@proton.me","estimated_minutes":60,"created_at":"2026-02-27T02:52:48.764658898Z","created_by":"Cecil","updated_at":"2026-02-27T03:26:21.730640011Z","closed_at":"2026-02-27T03:26:21.730642536Z","dependencies":[{"issue_id":"inference-budget-controller-s5d.8","depends_on_id":"inference-budget-controller-s5d","type":"parent-child","created_at":"2026-02-27T02:52:48.765346279Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-s5d.9","title":"E2E Testing Suite","description":"Implement comprehensive end-to-end tests using kind (Kubernetes in Docker) and Ginkgo.\n\n## Test Infrastructure\n\n- Use **kind** for local Kubernetes clusters\n- Use **Ginkgo** + **Gomega** for test framework\n- Create custom test fixtures for model deployments\n\n## Test Categories\n\n### 1. Controller E2E Tests\n\n```go\nDescribe(\"InferenceModel Controller\", func() {\n    It(\"should create Deployment when InferenceModel is created\", func() {\n        // Create InferenceModel CRD\n        // Verify Deployment exists with correct spec\n        // Verify status is updated\n    })\n    \n    It(\"should scale to zero after idle timeout\", func() {\n        // Create InferenceModel with short idle timeout\n        // Wait for idle period\n        // Verify replicas = 0\n    })\n    \n    It(\"should handle deletion with finalizer\", func() {\n        // Create InferenceModel\n        // Delete it\n        // Verify cleanup happens\n    })\n})\n```\n\n### 2. Budget Tracker E2E Tests\n\n```go\nDescribe(\"Budget Tracker\", func() {\n    It(\"should track memory allocation per node\", func() {\n        // Create multiple models\n        // Verify memory is tracked correctly\n    })\n    \n    It(\"should report utilization metrics\", func() {\n        // Create model with 80Gi declared\n        // Simulate 75Gi actual usage\n        // Verify utilization ~94%\n    })\n    \n    It(\"should generate recommendations\", func() {\n        // Create overprovisioned model\n        // Verify recommendation is generated\n    })\n})\n```\n\n### 3. API Proxy E2E Tests\n\n```go\nDescribe(\"API Proxy\", func() {\n    It(\"should proxy requests to running model\", func() {\n        // Scale model to 1\n        // Send chat completion request\n        // Verify response from backend\n    })\n    \n    It(\"should return 429 when insufficient memory\", func() {\n        // Fill node with model-a (80Gi on 128Gi node)\n        // Request model-b (60Gi)\n        // Verify 429 with blocking info\n    })\n    \n    It(\"should trigger scale-up on request\", func() {\n        // Model at 0 replicas\n        // Send request\n        // Verify model scales up\n        // Verify request completes\n    })\n    \n    It(\"should wait for cold start\", func() {\n        // Model at 0 replicas\n        // Send request\n        // Verify wait behavior\n        // Verify eventual success\n    })\n})\n```\n\n### 4. Admission Control E2E Tests\n\n```go\nDescribe(\"Admission Control\", func() {\n    It(\"should reject when node is full\", func() {\n        // Fill node\n        // Request new model\n        // Verify 429 with available memory info\n    })\n    \n    It(\"should include blocking models in error\", func() {\n        // Run model-a idle\n        // Request model-b that doesn't fit\n        // Verify blocking includes model-a with idle duration\n    })\n    \n    It(\"should allow request after model scales down\", func() {\n        // Run model-a, make it idle\n        // Wait for scale to zero\n        // Request model-b\n        // Verify success\n    })\n})\n```\n\n### 5. Observability E2E Tests\n\n```go\nDescribe(\"Observability\", func() {\n    It(\"should expose Prometheus metrics\", func() {\n        // Create model\n        // Scrape /metrics\n        // Verify expected metrics present\n    })\n    \n    It(\"should update CRD status with utilization\", func() {\n        // Create model\n        // Generate traffic\n        // Check status has observedPeakMemory\n    })\n    \n    It(\"should provide recommendation for overprovisioned model\", func() {\n        // Create overprovisioned model\n        // Wait for observation period\n        // Check status has recommendation\n    })\n})\n```\n\n## Test Setup\n\n```go\n// test/e2e/e2e_suite_test.go\nfunc TestE2E(t *testing.T) {\n    RegisterFailHandler(Fail)\n    RunSpecs(t, \"E2E Suite\")\n}\n\nvar _ = BeforeSuite(func() {\n    // 1. Create kind cluster\n    // 2. Build and load controller image\n    // 3. Install CRDs\n    // 4. Deploy controller\n    // 5. Wait for readiness\n})\n\nvar _ = AfterSuite(func() {\n    // Delete kind cluster\n})\n```\n\n## Makefile Targets\n\n```makefile\ntest-e2e:\n\\tginkgo -v ./test/e2e/...\n\ntest-e2e-quick:\n\\tginkgo -v --label-filter=\"!slow\" ./test/e2e/...\n\nkind-create:\n\\tkind create cluster --name inference-test\n\nkind-delete:\n\\tkind delete cluster --name inference-test\n```\n\n## Tasks\n\n1. Create `test/e2e/` directory structure\n2. Set up Ginkgo suite with kind cluster\n3. Implement controller e2e tests\n4. Implement budget tracker e2e tests\n5. Implement API proxy e2e tests\n6. Implement admission control e2e tests\n7. Implement observability e2e tests\n8. Add Makefile targets\n9. Add to CI workflow\n\n## Acceptance Criteria\n\n- [ ] Kind cluster created/destroyed automatically\n- [ ] All test categories implemented\n- [ ] Tests pass consistently\n- [ ] Tests run in CI pipeline\n- [ ] Test coverage for all critical paths\n- [ ] Tests clean up resources properly","status":"closed","priority":0,"issue_type":"feature","owner":"cecilthecoder@proton.me","estimated_minutes":240,"created_at":"2026-02-27T02:53:48.613913278Z","created_by":"Cecil","updated_at":"2026-02-27T04:00:39.589573735Z","closed_at":"2026-02-27T04:00:39.589580277Z","dependencies":[{"issue_id":"inference-budget-controller-s5d.9","depends_on_id":"inference-budget-controller-s5d","type":"parent-child","created_at":"2026-02-27T02:53:48.61477279Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-s5d.9","depends_on_id":"inference-budget-controller-s5d.4","type":"blocks","created_at":"2026-02-27T02:53:48.615916231Z","created_by":"Cecil"},{"issue_id":"inference-budget-controller-s5d.9","depends_on_id":"inference-budget-controller-s5d.5","type":"blocks","created_at":"2026-02-27T02:53:48.616907548Z","created_by":"Cecil"}]}
{"id":"inference-budget-controller-zxf","title":"Delete unused OpenAI response/request types from openai.go","description":"Remove all typed structs that are no longer needed after the pass-through refactor: ChatCompletionRequest, CompletionRequest, ChatMessage, ChatCompletionResponse, ChatChoice, CompletionResponse, CompletionChoice, StreamingChatCompletionChunk, StreamingChatChoiceChunk, ChatMessageDelta, Logprobs, UsageInfo, and their GetModelName/IsStream methods. Keep: ErrorResponse, ErrorDetail, ModelsResponse, ModelInfo, ModelListEntry, InsufficientMemoryDetails, BlockingModel, RequestedInfo, NewInsufficientMemoryResponse, InsufficientMemoryResponse.","status":"closed","priority":1,"issue_type":"task","owner":"cecilthecoder@proton.me","created_at":"2026-02-27T16:03:16.345742173-07:00","created_by":"Cecil","updated_at":"2026-02-27T16:11:49.090412215-07:00","closed_at":"2026-02-27T16:11:49.090412215-07:00","close_reason":"Handlers unified into openaiPassthroughHandler + forwardToBackend. All unused OpenAI types deleted. Build and tests pass.","dependencies":[{"issue_id":"inference-budget-controller-zxf","depends_on_id":"inference-budget-controller-3bv","type":"blocks","created_at":"2026-02-27T16:03:24.263825633-07:00","created_by":"Cecil"}]}
